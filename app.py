import os
import tempfile
import streamlit as st
from streamlit_chat import message
from dotenv import load_dotenv

from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains import ConversationalRetrievalChain
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import LlamaCpp

st.set_page_config(page_title="LLaMA PDF Chatbot", page_icon="ğŸ¦™")

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… ì–¸ì–´ ì„ íƒ
lang = st.sidebar.selectbox("Language / ì–¸ì–´ ì„ íƒ", ("í•œêµ­ì–´", "English"))

# âœ… ë‹¤êµ­ì–´ ë©”ì‹œì§€ ì •ì˜
messages = {
    "í•œêµ­ì–´": {
        "page_title": "LLaMA ê¸°ë°˜ PDF ì±—ë´‡",
        "page_description": "PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”.",
        "file_uploader": "ğŸ“„ PDF ì—…ë¡œë“œ",
        "input_label": "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        "input_placeholder": "ì˜ˆ: 2í˜ì´ì§€ ìš”ì•½í•´ì¤˜",
        "send_button": "ë³´ë‚´ê¸°",
        "init_greeting_user": "ì•ˆë…•í•˜ì„¸ìš”!",
        "init_greeting_bot": "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì„œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."
    },
    "English": {
        "page_title": "LLaMA-based PDF Chatbot",
        "page_description": "Upload a PDF and ask your questions freely.",
        "file_uploader": "ğŸ“„ Upload PDF",
        "input_label": "Enter your question",
        "input_placeholder": "e.g., Summarize page 2",
        "send_button": "Send",
        "init_greeting_user": "Hello!",
        "init_greeting_bot": "Hello! Ask me anything about the uploaded document."
    }
}

msg = messages[lang]

# âœ… í˜ì´ì§€ UI ì¶œë ¥
st.title(f"ğŸ¦™ {msg['page_title']}")
st.markdown(msg["page_description"])

# âœ… PDF ì—…ë¡œë“œ
uploaded_file = st.sidebar.file_uploader(msg["file_uploader"], type="pdf")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name

    # âœ… ë¬¸ì„œ ë¡œë“œ
    loader = PyPDFLoader(tmp_path)
    data = loader.load()

    # âœ… ì„ë² ë”© ìƒì„± (CPU ê°•ì œ ì„¤ì •)
    embeddings = HuggingFaceEmbeddings(
        model_name="intfloat/e5-small-v2",
        model_kwargs={"device": "cpu"}
    )
    vectordb = FAISS.from_documents(data, embeddings)

    # âœ… LLaMA ëª¨ë¸ ë¡œë”©
    llm = LlamaCpp(
        model_path="./models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
        temperature=0.0,
        max_tokens=1024,
        n_ctx=2048,
        verbose=True,
    )

    # âœ… RAG ì²´ì¸ êµ¬ì„±
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectordb.as_retriever()
    )

    # âœ… ì„¸ì…˜ ì´ˆê¸°í™”
    if "history" not in st.session_state:
        st.session_state["history"] = []
    if "generated" not in st.session_state:
        st.session_state["generated"] = [msg["init_greeting_bot"]]
    if "past" not in st.session_state:
        st.session_state["past"] = [msg["init_greeting_user"]]

    # âœ… ì§ˆë¬¸ ì…ë ¥ í¼
    with st.container():
        with st.form("chat_form", clear_on_submit=True):
            user_input = st.text_input(msg["input_label"], placeholder=msg["input_placeholder"])
            submitted = st.form_submit_button(label=msg["send_button"])

            if submitted and user_input:
                # âœ… í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™”: ì‚¬ìš©ì ì§ˆë¬¸ë§Œ ì „ë‹¬
                result = chain({
                    "question": user_input,
                    "chat_history": st.session_state["history"]
                })
                answer = result["answer"]

                st.session_state["past"].append(user_input)
                st.session_state["generated"].append(answer)
                st.session_state["history"].append((user_input, answer))

    # âœ… ëŒ€í™” ì¶œë ¥
    if st.session_state["generated"]:
        with st.container():
            for i in range(len(st.session_state["generated"])):
                message(st.session_state["past"][i], is_user=True, key=f"user_{i}", avatar_style="fun-emoji")
                message(st.session_state["generated"][i], key=f"bot_{i}", avatar_style="bottts")
